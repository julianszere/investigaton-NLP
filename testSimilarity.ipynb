{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3bad9081",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from transformer_lens import HookedTransformer\n",
    "from sae_lens import SAE\n",
    "from src.agents.RAGAgent import embed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "853d4e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total RAM: 15.42 GB\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "ram_gb = psutil.virtual_memory().total / (1024**3)\n",
    "print(f\"Total RAM: {ram_gb:.2f} GB\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e89ad67",
   "metadata": {},
   "source": [
    "# RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cb84f02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7175bb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_similarity(context, pos_query, neg_query):\n",
    "    model = 'ollama/nomic-embed-text'\n",
    "    z_context = embed_text(context, model)\n",
    "    z_pos_query = embed_text(pos_query, model)\n",
    "    z_neg_query = embed_text(neg_query, model)\n",
    "\n",
    "    return np.dot(z_context, z_pos_query), np.dot(z_context, z_neg_query)\n",
    "    #print(f'RAG similarity: {np.dot(z1_norm, z2_norm)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5b564b",
   "metadata": {},
   "source": [
    "# SAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33d239c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35c23352",
   "metadata": {},
   "outputs": [],
   "source": [
    "sae_base_model_name = \"EleutherAI/pythia-70m-deduped\"\n",
    "sae_release = \"ctigges/pythia-70m-deduped__res-sm_processed\"\n",
    "sae_id      = \"4-res-sm\"\n",
    "hook_name   = \"blocks.4.hook_resid_post\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "756d55d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sae_base_model_name = \"gemma-2b-it\"\n",
    "sae_release = \"gemma-2b-it-res-jb\"\n",
    "sae_id = \"blocks.12.hook_resid_post\"\n",
    "hook_name = \"blocks.12.hook_resid_post\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8247311c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:37<00:00, 18.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gemma-2b-it into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "sae_base_model = HookedTransformer.from_pretrained_no_processing(\n",
    "    sae_base_model_name,\n",
    "    device=device,\n",
    "    dtype=torch.float16,   # float32 is safest on CPU\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a3ee4c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_46706/1603754695.py:1: DeprecationWarning: Unpacking SAE objects is deprecated. SAE.from_pretrained() now returns only the SAE object. Use SAE.from_pretrained_with_cfg_and_sparsity() to get the config dict and sparsity as well.\n",
      "  sae, sae_cfg, sparsity = SAE.from_pretrained(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StandardSAE(\n",
       "  (activation_fn): ReLU()\n",
       "  (hook_sae_input): HookPoint()\n",
       "  (hook_sae_acts_pre): HookPoint()\n",
       "  (hook_sae_acts_post): HookPoint()\n",
       "  (hook_sae_output): HookPoint()\n",
       "  (hook_sae_recons): HookPoint()\n",
       "  (hook_sae_error): HookPoint()\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sae, sae_cfg, sparsity = SAE.from_pretrained(\n",
    "    release=sae_release,\n",
    "    sae_id=sae_id,\n",
    "    device=device,\n",
    ")\n",
    "sae.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9625de46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sae_encode_text(\n",
    "    model, \n",
    "    sae, \n",
    "    text, \n",
    "    hook_name, \n",
    "    prepend_bos=True, \n",
    "    method=\"mean\",   # \"mean\", \"max\", or \"topk\"\n",
    "    k=3\n",
    "):\n",
    "    with torch.no_grad():\n",
    "        tokens = model.to_tokens(text, prepend_bos=prepend_bos)\n",
    "        _, cache = model.run_with_cache(tokens, names_filter=[hook_name])\n",
    "        acts = cache[hook_name]              # [batch, seq, d_model]\n",
    "        acts_no_bos = acts[:, 1:, :]         # [batch, seq-1, d_model]\n",
    "        feature_acts = sae.encode(acts_no_bos)  # [batch, seq-1, n_features]\n",
    "\n",
    "        # ------- Aggregation methods -------\n",
    "        if method == \"mean\":\n",
    "            z = feature_acts.mean(dim=1)     # [B, F]\n",
    "\n",
    "        elif method == \"max\":\n",
    "            z = feature_acts.max(dim=1).values  # [B, F]\n",
    "\n",
    "        elif method == \"topk\":\n",
    "            seq_len = feature_acts.shape[1]\n",
    "            k_eff = min(k, seq_len)\n",
    "            topk_vals, _ = torch.topk(feature_acts, k=k_eff, dim=1)\n",
    "            z = topk_vals.mean(dim=1)        # [B, F]\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown method '{method}', choose from 'mean', 'max', 'topk'.\")\n",
    "\n",
    "        # Final vector\n",
    "        z = z.squeeze(0).cpu().numpy()\n",
    "        return z / np.linalg.norm(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2e70dd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tanimoto_similarity(z1, z2):\n",
    "    dot = np.dot(z1, z2)\n",
    "    denom = np.dot(z1, z1) + np.dot(z2, z2) - dot\n",
    "    return dot / denom if denom != 0 else 0.0\n",
    "\n",
    "def jaccard_similarity(z1, z2):\n",
    "    f1 = set(np.nonzero(z1)[0])\n",
    "    f2 = set(np.nonzero(z2)[0])\n",
    "    return len(f1 & f2) / len(f1 | f2)\n",
    "\n",
    "def sae_similarity(context, pos_query, neg_query, method=\"topk\", k=3):\n",
    "    z_context = sae_encode_text(sae_base_model, sae, context, hook_name, method=method, k=k)\n",
    "    z_pos_query = sae_encode_text(sae_base_model, sae, pos_query, hook_name, method=method, k=k)\n",
    "    z_neg_query = sae_encode_text(sae_base_model, sae, neg_query, hook_name, method=method, k=k)\n",
    "    return np.dot(z_context, z_pos_query), np.dot(z_context, z_neg_query)\n",
    "    #return tanimoto_similarity(z_context, z_pos_query), tanimoto_similarity(z_context, z_neg_query)\n",
    "    #return jaccard_similarity(z_context, z_pos_query), jaccard_similarity(z_context, z_neg_query)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f714cc1b",
   "metadata": {},
   "source": [
    "# SAE vs RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d50a72c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(context, pos_query, neg_query):\n",
    "    return rag_similarity(context, pos_query, neg_query), sae_similarity(context, pos_query, neg_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0892ce68",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    # Example 1\n",
    "    dict(\n",
    "        context=(\n",
    "            \"User: Which one would you say is the best for a romantic dinner?\\n\"\n",
    "            \"Assistant: I would recommend Roscioli. It has a cozy and intimate atmosphere \"\n",
    "            \"with soft lighting and excellent service.\"\n",
    "        ),\n",
    "        pos_query=\"Can you remind me of the romantic restaurant in Rome you recommended for dinner?\",\n",
    "        neg_query=\"Can you remind me which museum in Rome you said had the best collection of ancient sculptures?\",\n",
    "    ),\n",
    "\n",
    "    # Example 2\n",
    "    dict(\n",
    "        context=(\n",
    "            \"User: I want a compact camera for street photography, something small but with great image quality. \"\n",
    "            \"Any suggestions?\\n\"\n",
    "            \"Assistant: You might really like the Ricoh GR III. It’s very pocketable and has an excellent \"\n",
    "            \"28mm-equivalent lens that’s great for street shots.\"\n",
    "        ),\n",
    "        pos_query=\"What was the small street photography camera you suggested, the one with the 28mm lens?\",\n",
    "        neg_query=\"What was the tripod you recommended for long-exposure night photography?\",\n",
    "    ),\n",
    "\n",
    "    # Example 3\n",
    "    dict(\n",
    "        context=(\n",
    "            \"User: My API is slowing down under load. Could it be the Docker configuration?\\n\"\n",
    "            \"Assistant: It’s possible. I’d start by checking the CPU and memory limits on the container \"\n",
    "            \"and see if you’re hitting them during peak traffic.\"\n",
    "        ),\n",
    "        pos_query=\"What did you say I should look at in my Docker setup to understand why the API slows down?\",\n",
    "        neg_query=\"What did you say I should look at in my Postgres configuration to reduce slow queries?\",\n",
    "    ),\n",
    "\n",
    "    # Example 4\n",
    "    dict(\n",
    "        context=(\n",
    "            \"User: I’m trying to choose between airlines for a long-haul flight to Tokyo. Any preference?\\n\"\n",
    "            \"Assistant: If you can, go with ANA. Their economy seats are more comfortable and the service \"\n",
    "            \"is consistently excellent.\"\n",
    "        ),\n",
    "        pos_query=\"Which airline did you say was better for my long flight to Tokyo?\",\n",
    "        neg_query=\"Which website did you say was best for finding cheap hotel deals in Tokyo?\",\n",
    "    ),\n",
    "\n",
    "    # Example 5\n",
    "    dict(\n",
    "        context=(\n",
    "            \"User: I have an exam in statistical mechanics next month and I’m overwhelmed. \"\n",
    "            \"How should I structure my study time?\\n\"\n",
    "            \"Assistant: Focus first on the partition function and the main ensembles. Then spend time on typical \"\n",
    "            \"problems with phase transitions and critical exponents, and leave the more exotic topics for last.\"\n",
    "        ),\n",
    "        pos_query=\"What did you tell me to prioritize when studying for my statistical mechanics exam?\",\n",
    "        neg_query=\"What did you tell me to prioritize when preparing my job interview presentation?\",\n",
    "    ),\n",
    "\n",
    "    # Example 6\n",
    "    dict(\n",
    "        context=(\n",
    "            \"User: I need a laptop for machine learning experiments. Any particular specs I should aim for?\\n\"\n",
    "            \"Assistant: Try to get at least 32 GB of RAM and an NVIDIA GPU with at least 8 GB of VRAM. \"\n",
    "            \"That will make training small to medium models much smoother.\"\n",
    "        ),\n",
    "        pos_query=\"Can you remind me what specs you recommended for a laptop to run my ML experiments?\",\n",
    "        neg_query=\"Can you remind me what specs you recommended for a monitor for photo editing?\",\n",
    "    ),\n",
    "\n",
    "    # Example 7\n",
    "    dict(\n",
    "        context=(\n",
    "            \"User: I’m visiting Barcelona for a few days and want a nice day hike nearby. Any suggestions?\\n\"\n",
    "            \"Assistant: You could hike in Montserrat. It’s about an hour from the city by train and has beautiful \"\n",
    "            \"mountain views and well-marked trails.\"\n",
    "        ),\n",
    "        pos_query=\"What was the hiking spot near Barcelona you mentioned that I can reach by train?\",\n",
    "        neg_query=\"What was the beach town near Barcelona you mentioned that’s good for a day of swimming?\",\n",
    "    ),\n",
    "\n",
    "    # Example 8\n",
    "    dict(\n",
    "        context=(\n",
    "            \"User: I want a sci-fi novel that’s thoughtful but still fun to read. Any ideas?\\n\"\n",
    "            \"Assistant: You might enjoy \\\"The Three-Body Problem.\\\" It mixes hard science with a very engaging story.\"\n",
    "        ),\n",
    "        pos_query=\"Which sci-fi book did you recommend that combines hard science with an engaging story?\",\n",
    "        neg_query=\"Which non-fiction book did you recommend for learning basic investing principles?\",\n",
    "    ),\n",
    "    {\n",
    "    \"context\": (\n",
    "        \"User: I'm finally replacing my old laptop. Do you think 16GB of RAM is enough for light coding?\\n\"\n",
    "        \"Assistant: For light coding it's fine, but if you plan to do ML experiments or heavy multitasking, \"\n",
    "        \"I'd recommend going for 32GB instead.\"\n",
    "    ),\n",
    "    \"pos_query\": \"What was the RAM amount you recommended for heavier ML coding workloads?\",\n",
    "    \"neg_query\": \"What was the phone model you said had the best battery life for traveling?\"\n",
    "    },\n",
    "    {\n",
    "        \"context\": (\n",
    "            \"User: I'm planning a trip to Florence. Is there a museum I absolutely shouldn't miss?\\n\"\n",
    "            \"Assistant: Definitely visit the Uffizi Gallery. It's one of the most important art museums in the world.\"\n",
    "        ),\n",
    "        \"pos_query\": \"What was the museum in Florence you told me I shouldn't miss?\",\n",
    "        \"neg_query\": \"Which restaurant in Florence did you say had the best bistecca alla fiorentina?\"\n",
    "    },\n",
    "\n",
    "    {\n",
    "        \"context\": (\n",
    "            \"User: I'm choosing a film camera for trying analog photography. Any recommendation?\\n\"\n",
    "            \"Assistant: The Nikon FE is a great starting point. Reliable, sturdy, and easy to use.\"\n",
    "        ),\n",
    "        \"pos_query\": \"Which beginner film camera did you recommend to me?\",\n",
    "        \"neg_query\": \"What digital camera did you say was best for recording 4K video?\"\n",
    "    },\n",
    "\n",
    "    {\n",
    "        \"context\": (\n",
    "            \"User: My sourdough bread keeps coming out too dense. What should I fix?\\n\"\n",
    "            \"Assistant: Try increasing the hydration slightly and give the dough a longer bulk fermentation.\"\n",
    "        ),\n",
    "        \"pos_query\": \"What did you say I should adjust in my sourdough recipe to avoid dense loaves?\",\n",
    "        \"neg_query\": \"What did you say I should adjust in my lasagna recipe to make the sauce thicker?\"\n",
    "    },\n",
    "\n",
    "    {\n",
    "        \"context\": (\n",
    "            \"User: I'm thinking of learning a second programming language after Python. Suggestions?\\n\"\n",
    "            \"Assistant: Go with Rust. It forces good habits and teaches you a lot about memory safety and performance.\"\n",
    "        ),\n",
    "        \"pos_query\": \"Which programming language did you recommend I learn after Python?\",\n",
    "        \"neg_query\": \"Which photo editing software did you recommend for color grading RAW images?\"\n",
    "    },\n",
    "\n",
    "    {\n",
    "        \"context\": (\n",
    "            \"User: I want something philosophical but easy to read. Any book recommendations?\\n\"\n",
    "            \"Assistant: You might like 'The Stranger' by Albert Camus. It's short but very thought-provoking.\"\n",
    "        ),\n",
    "        \"pos_query\": \"Which philosophical novel did you recommend that was short and thought-provoking?\",\n",
    "        \"neg_query\": \"Which fantasy novel did you recommend that had dragons and magic?\"\n",
    "    },\n",
    "\n",
    "    {\n",
    "        \"context\": (\n",
    "            \"User: I'm trying intermittent fasting for the first time. Any tips for beginners?\\n\"\n",
    "            \"Assistant: Start with a 14:10 schedule and gradually increase the fasting window if you feel comfortable.\"\n",
    "        ),\n",
    "        \"pos_query\": \"What fasting schedule did you say was good for beginners?\",\n",
    "        \"neg_query\": \"What running schedule did you say was good for preparing a marathon?\"\n",
    "    },\n",
    "\n",
    "    {\n",
    "        \"context\": (\n",
    "            \"User: My code is running much slower after I moved to Windows from Linux. Any ideas?\\n\"\n",
    "            \"Assistant: Check whether Windows Defender is scanning your Python files. That often slows down execution.\"\n",
    "        ),\n",
    "        \"pos_query\": \"What did you say might be slowing down my Python code on Windows?\",\n",
    "        \"neg_query\": \"What did you say might be causing my internet to disconnect randomly?\"\n",
    "    },\n",
    "\n",
    "    {\n",
    "        \"context\": (\n",
    "            \"User: I'm decorating my apartment and want a minimalist look. Any advice?\\n\"\n",
    "            \"Assistant: Stick to neutral colors and reduce visible clutter. Furniture with clean lines works best.\"\n",
    "        ),\n",
    "        \"pos_query\": \"What kind of design recommendations did you give me for a minimalist apartment?\",\n",
    "        \"neg_query\": \"What kind of exercise recommendations did you give me for building muscle?\"\n",
    "    },\n",
    "\n",
    "    {\n",
    "        \"context\": (\n",
    "            \"User: I'm learning guitar but my fingers hurt a lot. Is that normal?\\n\"\n",
    "            \"Assistant: Yes, totally normal. You'll develop calluses after a few weeks and the pain will decrease.\"\n",
    "        ),\n",
    "        \"pos_query\": \"What did you say would eventually stop hurting when practicing guitar?\",\n",
    "        \"neg_query\": \"What did you say would eventually improve if I keep practicing my coding skills?\"\n",
    "    }\n",
    "\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cde4c968",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_method(backend, method=None, k=None):\n",
    "    \"\"\"\n",
    "    backend: \"rag\" or \"sae\"\n",
    "    method, k: passed through to sae_similarity when backend == \"sae\"\n",
    "    \"\"\"\n",
    "    related = []\n",
    "    unrelated = []\n",
    "\n",
    "    for ex in examples:\n",
    "        if backend == \"rag\":\n",
    "            pos, neg = rag_similarity(\n",
    "                ex[\"context\"],\n",
    "                ex[\"pos_query\"],\n",
    "                ex[\"neg_query\"],\n",
    "            )\n",
    "        elif backend == \"sae\":\n",
    "            pos, neg = sae_similarity(\n",
    "                ex[\"context\"],\n",
    "                ex[\"pos_query\"],\n",
    "                ex[\"neg_query\"],\n",
    "                method,\n",
    "                k,\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown backend: {backend}. Use 'rag' or 'sae'.\")\n",
    "\n",
    "        related.append(pos)\n",
    "        unrelated.append(neg)\n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    related = np.array(related)\n",
    "    unrelated = np.array(unrelated)\n",
    "\n",
    "    # Helper to compute propagated error of the separation\n",
    "    def compute_sep_error(std_rel, std_unrel, n):\n",
    "        se_rel = std_rel / np.sqrt(n)\n",
    "        se_unrel = std_unrel / np.sqrt(n)\n",
    "        return float(np.sqrt(se_rel**2 + se_unrel**2))\n",
    "\n",
    "    std_rel = float(related.std())\n",
    "    std_unrel = float(unrelated.std())\n",
    "    n = len(related)\n",
    "\n",
    "    stats = {\n",
    "        \"backend\": backend,  # \"rag\" or \"sae\"\n",
    "        \"mean_related\": float(related.mean()),\n",
    "        \"std_related\": std_rel,\n",
    "        \"mean_unrelated\": float(unrelated.mean()),\n",
    "        \"std_unrelated\": std_unrel,\n",
    "        \"separation\": float(related.mean() - unrelated.mean()),\n",
    "        \"separation_error\": compute_sep_error(std_rel, std_unrel, n),\n",
    "        \"n\": n,\n",
    "    }\n",
    "\n",
    "    return stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e47175",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_separation(stats_list, labels):\n",
    "    separations = [s[\"separation\"] for s in stats_list]\n",
    "    errors = [s[\"separation_error\"] for s in stats_list]\n",
    "\n",
    "    # For debugging if needed\n",
    "    # print(\"separations:\", separations)\n",
    "    # print(\"errors:\", errors)\n",
    "\n",
    "    # Build a small DataFrame so seaborn is happy\n",
    "    df = pd.DataFrame({\n",
    "        \"method\": labels,\n",
    "        \"separation\": separations,\n",
    "        \"error\": errors,\n",
    "    })\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "\n",
    "    # Draw bars with seaborn (no built-in yerr here, so ci=None)\n",
    "    ax = sns.barplot(\n",
    "        data=df,\n",
    "        x=\"method\",\n",
    "        y=\"separation\",\n",
    "        ci=None,          # don't let seaborn compute its own error bars\n",
    "    )\n",
    "\n",
    "    # Add our own error bars with matplotlib\n",
    "    x_positions = np.arange(len(df))\n",
    "    ax.errorbar(\n",
    "        x=x_positions,\n",
    "        y=df[\"separation\"],\n",
    "        yerr=df[\"error\"],\n",
    "        fmt=\"none\",\n",
    "        capsize=5,\n",
    "        color=\"black\",\n",
    "        linewidth=1.5,\n",
    "    )\n",
    "\n",
    "    ax.set_ylabel(\"Separation\")\n",
    "    ax.set_xlabel(\"\")\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "33898983",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_stats = test_method('rag')\n",
    "sae_mean_stats = test_method('sae', method=\"mean\")\n",
    "sae_max_stats = test_method('sae', method=\"max\")\n",
    "sae_top3_stats = test_method('sae', method=\"topk\", k=3)\n",
    "sae_top10_stats = test_method('sae', method=\"mean\", k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "da18261e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_46706/14139244.py:19: FutureWarning: \n",
      "\n",
      "The `ci` parameter is deprecated. Use `errorbar=None` for the same effect.\n",
      "\n",
      "  ax = sns.barplot(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_separation([rag_stats, sae_mean_stats, sae_max_stats, sae_top3_stats, sae_top10_stats], ['Baseline', 'SAE Mean', 'SAE Max', 'SAE Top-3', 'SAE Top-10'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e00136e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== RAG SIMILARITY ==========\n",
      "Mean related similarity   : 0.7980174615796013 0.0447352891689297\n",
      "Mean unrelated similarity : 0.5882399145760032 0.06277481162354855\n",
      "Separation (related - unrelated): 0.20977754700359807\n",
      "\n",
      "========== SAE SIMILARITY ==========\n",
      "Mean related similarity   : 0.3673504 0.060817957\n",
      "Mean unrelated similarity : 0.18679272 0.06621986\n",
      "Separation (related - unrelated): 0.18055768\n",
      "\n",
      "Counts -> related: 18 unrelated: 18\n"
     ]
    }
   ],
   "source": [
    "test_method(\"max\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ded47c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== RAG SIMILARITY ==========\n",
      "Mean related similarity   : 0.7980174615796013 0.0447352891689297\n",
      "Mean unrelated similarity : 0.5882399145760032 0.06277481162354855\n",
      "Separation (related - unrelated): 0.20977754700359807\n",
      "\n",
      "========== SAE SIMILARITY ==========\n",
      "Mean related similarity   : 0.43167365 0.06786506\n",
      "Mean unrelated similarity : 0.2562137 0.059962727\n",
      "Separation (related - unrelated): 0.17545995\n",
      "\n",
      "Counts -> related: 18 unrelated: 18\n"
     ]
    }
   ],
   "source": [
    "test_method(\"topk\", k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9a3aac35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== RAG SIMILARITY ==========\n",
      "Mean related similarity   : 0.7980174615796013 0.0447352891689297\n",
      "Mean unrelated similarity : 0.5882399145760032 0.06277481162354855\n",
      "Separation (related - unrelated): 0.20977754700359807\n",
      "\n",
      "========== SAE SIMILARITY ==========\n",
      "Mean related similarity   : 0.4598261 0.06515279\n",
      "Mean unrelated similarity : 0.29110044 0.061601207\n",
      "Separation (related - unrelated): 0.16872567\n",
      "\n",
      "Counts -> related: 18 unrelated: 18\n"
     ]
    }
   ],
   "source": [
    "test_method(\"topk\", k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0d68b7d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== RAG SIMILARITY ==========\n",
      "Mean related similarity   : 0.7980174615796013 0.0447352891689297\n",
      "Mean unrelated similarity : 0.5882399145760032 0.06277481162354855\n",
      "Separation (related - unrelated): 0.20977754700359807\n",
      "\n",
      "========== SAE SIMILARITY ==========\n",
      "Mean related similarity   : 0.47961175 0.07108512\n",
      "Mean unrelated similarity : 0.30776542 0.068244085\n",
      "Separation (related - unrelated): 0.17184633\n",
      "\n",
      "Counts -> related: 18 unrelated: 18\n"
     ]
    }
   ],
   "source": [
    "test_method(\"topk\", k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6fd6844a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Context (conversation):\n",
      "User: I want a sci-fi novel that’s thoughtful but still fun to read. Any ideas?\n",
      "Assistant: You might enjoy \"The Three-Body Problem.\" It mixes hard science with a very engaging story.\n",
      "\n",
      "RAG separation: 0.1755\n",
      "SAE separation: 0.3364\n",
      "SAE - RAG      : 0.1609\n",
      "\n",
      "Related (pos_query) and sims:\n",
      "  [RAG=0.7535, SAE=0.4608]  Which sci-fi book did you recommend that combines hard science with an engaging story?\n",
      "\n",
      "Unrelated (neg_query) and sims:\n",
      "  [RAG=0.5780, SAE=0.1244]  Which non-fiction book did you recommend for learning basic investing principles?\n",
      "\n",
      "================================================================================\n",
      "Context (conversation):\n",
      "User: I want a compact camera for street photography, something small but with great image quality. Any suggestions?\n",
      "Assistant: You might really like the Ricoh GR III. It’s very pocketable and has an excellent 28mm-equivalent lens that’s great for street shots.\n",
      "\n",
      "RAG separation: 0.1460\n",
      "SAE separation: 0.2407\n",
      "SAE - RAG      : 0.0947\n",
      "\n",
      "Related (pos_query) and sims:\n",
      "  [RAG=0.7889, SAE=0.4435]  What was the small street photography camera you suggested, the one with the 28mm lens?\n",
      "\n",
      "Unrelated (neg_query) and sims:\n",
      "  [RAG=0.6429, SAE=0.2028]  What was the tripod you recommended for long-exposure night photography?\n",
      "\n",
      "================================================================================\n",
      "Context (conversation):\n",
      "User: I want something philosophical but easy to read. Any book recommendations?\n",
      "Assistant: You might like 'The Stranger' by Albert Camus. It's short but very thought-provoking.\n",
      "\n",
      "RAG separation: 0.1989\n",
      "SAE separation: 0.2842\n",
      "SAE - RAG      : 0.0853\n",
      "\n",
      "Related (pos_query) and sims:\n",
      "  [RAG=0.7356, SAE=0.4219]  Which philosophical novel did you recommend that was short and thought-provoking?\n",
      "\n",
      "Unrelated (neg_query) and sims:\n",
      "  [RAG=0.5368, SAE=0.1377]  Which fantasy novel did you recommend that had dragons and magic?\n",
      "\n",
      "================================================================================\n",
      "Context (conversation):\n",
      "User: I'm choosing a film camera for trying analog photography. Any recommendation?\n",
      "Assistant: The Nikon FE is a great starting point. Reliable, sturdy, and easy to use.\n",
      "\n",
      "RAG separation: 0.1174\n",
      "SAE separation: 0.1515\n",
      "SAE - RAG      : 0.0341\n",
      "\n",
      "Related (pos_query) and sims:\n",
      "  [RAG=0.7713, SAE=0.3881]  Which beginner film camera did you recommend to me?\n",
      "\n",
      "Unrelated (neg_query) and sims:\n",
      "  [RAG=0.6539, SAE=0.2366]  What digital camera did you say was best for recording 4K video?\n",
      "\n",
      "================================================================================\n",
      "Context (conversation):\n",
      "User: I’m trying to choose between airlines for a long-haul flight to Tokyo. Any preference?\n",
      "Assistant: If you can, go with ANA. Their economy seats are more comfortable and the service is consistently excellent.\n",
      "\n",
      "RAG separation: 0.1561\n",
      "SAE separation: 0.1814\n",
      "SAE - RAG      : 0.0252\n",
      "\n",
      "Related (pos_query) and sims:\n",
      "  [RAG=0.7954, SAE=0.3677]  Which airline did you say was better for my long flight to Tokyo?\n",
      "\n",
      "Unrelated (neg_query) and sims:\n",
      "  [RAG=0.6392, SAE=0.1864]  Which website did you say was best for finding cheap hotel deals in Tokyo?\n",
      "\n",
      "================================================================================\n",
      "Context (conversation):\n",
      "User: I'm planning a trip to Florence. Is there a museum I absolutely shouldn't miss?\n",
      "Assistant: Definitely visit the Uffizi Gallery. It's one of the most important art museums in the world.\n",
      "\n",
      "RAG separation: 0.1972\n",
      "SAE separation: 0.2024\n",
      "SAE - RAG      : 0.0053\n",
      "\n",
      "Related (pos_query) and sims:\n",
      "  [RAG=0.8006, SAE=0.4091]  What was the museum in Florence you told me I shouldn't miss?\n",
      "\n",
      "Unrelated (neg_query) and sims:\n",
      "  [RAG=0.6034, SAE=0.2066]  Which restaurant in Florence did you say had the best bistecca alla fiorentina?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "# 1) Run RAG + SAE on all examples and store results\n",
    "results = []\n",
    "for ex in examples:\n",
    "    context = ex[\"context\"]\n",
    "    pos_q = ex[\"pos_query\"]\n",
    "    neg_q = ex[\"neg_query\"]\n",
    "\n",
    "    rag_pos, rag_neg = rag_similarity(context, pos_q, neg_q)\n",
    "    sae_pos, sae_neg = sae_similarity(context, pos_q, neg_q, 'max')\n",
    "\n",
    "    results.append({\n",
    "        \"context\": context,\n",
    "        \"pos_query\": pos_q,\n",
    "        \"neg_query\": neg_q,\n",
    "        \"rag_pos\": rag_pos,\n",
    "        \"rag_neg\": rag_neg,\n",
    "        \"sae_pos\": sae_pos,\n",
    "        \"sae_neg\": sae_neg,\n",
    "    })\n",
    "\n",
    "# 2) Group by context (conversation)\n",
    "groups = defaultdict(list)\n",
    "for r in results:\n",
    "    groups[r[\"context\"]].append(r)\n",
    "\n",
    "# 3) For each group, compute separation for RAG and SAE\n",
    "group_summaries = []\n",
    "\n",
    "for context, group in groups.items():\n",
    "    rag_pos_vals = [g[\"rag_pos\"] for g in group]\n",
    "    rag_neg_vals = [g[\"rag_neg\"] for g in group]\n",
    "    sae_pos_vals = [g[\"sae_pos\"] for g in group]\n",
    "    sae_neg_vals = [g[\"sae_neg\"] for g in group]\n",
    "\n",
    "    # Need at least one related and one unrelated to define a separation\n",
    "    if not rag_pos_vals or not rag_neg_vals or not sae_pos_vals or not sae_neg_vals:\n",
    "        continue\n",
    "\n",
    "    rag_sep = np.mean(rag_pos_vals) - np.mean(rag_neg_vals)\n",
    "    sae_sep = np.mean(sae_pos_vals) - np.mean(sae_neg_vals)\n",
    "\n",
    "    group_summaries.append({\n",
    "        \"context\": context,\n",
    "        \"group\": group,\n",
    "        \"rag_sep\": rag_sep,\n",
    "        \"sae_sep\": sae_sep,\n",
    "        \"delta\": sae_sep - rag_sep,  # how much SAE beats RAG (if positive)\n",
    "    })\n",
    "\n",
    "# 4) Filter to where SAE outperforms RAG and sort by how much\n",
    "better_for_sae = [g for g in group_summaries if g[\"sae_sep\"] > g[\"rag_sep\"]]\n",
    "better_for_sae.sort(key=lambda g: g[\"delta\"], reverse=True)\n",
    "\n",
    "# 5) Pretty-print the cases where SAE > RAG\n",
    "for g in better_for_sae:\n",
    "    print(\"=\" * 80)\n",
    "    print(\"Context (conversation):\")\n",
    "    print(g[\"context\"])\n",
    "    print()\n",
    "    print(f\"RAG separation: {g['rag_sep']:.4f}\")\n",
    "    print(f\"SAE separation: {g['sae_sep']:.4f}\")\n",
    "    print(f\"SAE - RAG      : {g['delta']:.4f}\")\n",
    "\n",
    "    print(\"\\nRelated (pos_query) and sims:\")\n",
    "    for r in g[\"group\"]:\n",
    "        print(f\"  [RAG={r['rag_pos']:.4f}, SAE={r['sae_pos']:.4f}]  {r['pos_query']}\")\n",
    "\n",
    "    print(\"\\nUnrelated (neg_query) and sims:\")\n",
    "    for r in g[\"group\"]:\n",
    "        print(f\"  [RAG={r['rag_neg']:.4f}, SAE={r['sae_neg']:.4f}]  {r['neg_query']}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7cec3df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare(\n",
    "    \"User: I yelled at my sister yesterday and now she won’t talk to me.\\n\"\n",
    "    \"Assistant: That sounds painful. When something can’t be taken back, the focus becomes repairing trust.\\n\"\n",
    "    \"User: I wish I could undo it.\",\n",
    "    \"How do I deal with a mistake that I can’t take back?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "167fa233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG similarity: 0.5280847636696077\n",
      "SAE similarity: 0.15224242210388184\n"
     ]
    }
   ],
   "source": [
    "compare(\"He planted the seed in spring and waited months for anything to happen.\",\n",
    "        \"She submitted her PhD application and knew the results would arrive much later.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dbd87b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG similarity: 0.4709199426788174\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mcompare\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mOnce the glass shattered, there was no way back.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mWhen she sent the angry email, the relationship changed permanently.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 3\u001b[39m, in \u001b[36mcompare\u001b[39m\u001b[34m(text_1, text_2)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompare\u001b[39m(text_1, text_2):\n\u001b[32m      2\u001b[39m     rag_similarity(text_1, text_2)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     \u001b[43msae_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_2\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 3\u001b[39m, in \u001b[36msae_similarity\u001b[39m\u001b[34m(text_1, text_2)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msae_similarity\u001b[39m(text_1, text_2):\n\u001b[32m      2\u001b[39m     z1 = sae_encode_text(sae_base_model, sae, text_1, hook_name)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     z2 = \u001b[43msae_encode_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43msae_base_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msae\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m     z1_norm = z1 / np.linalg.norm(z1)\n\u001b[32m      6\u001b[39m     z2_norm = z2 / np.linalg.norm(z2)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/investigaton-NLP-1/src/agents/SAESearcherAgent.py:12\u001b[39m, in \u001b[36msae_encode_text\u001b[39m\u001b[34m(model, sae, text, hook_name, prepend_bos)\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m     11\u001b[39m     tokens = model.to_tokens(text, prepend_bos=prepend_bos)\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m     _, cache = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_with_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnames_filter\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m     acts = cache[hook_name]\n\u001b[32m     14\u001b[39m     acts_no_bos = acts[:, \u001b[32m1\u001b[39m:, :]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/investigaton-NLP-1/.venv/lib/python3.14/site-packages/transformer_lens/HookedTransformer.py:702\u001b[39m, in \u001b[36mHookedTransformer.run_with_cache\u001b[39m\u001b[34m(self, return_cache_object, remove_batch_dim, *model_args, **kwargs)\u001b[39m\n\u001b[32m    685\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun_with_cache\u001b[39m(\n\u001b[32m    686\u001b[39m     \u001b[38;5;28mself\u001b[39m, *model_args, return_cache_object=\u001b[38;5;28;01mTrue\u001b[39;00m, remove_batch_dim=\u001b[38;5;28;01mFalse\u001b[39;00m, **kwargs\n\u001b[32m    687\u001b[39m ) -> Tuple[\n\u001b[32m   (...)\u001b[39m\u001b[32m    694\u001b[39m     Union[ActivationCache, Dict[\u001b[38;5;28mstr\u001b[39m, torch.Tensor]],\n\u001b[32m    695\u001b[39m ]:\n\u001b[32m    696\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Wrapper around `run_with_cache` in HookedRootModule.\u001b[39;00m\n\u001b[32m    697\u001b[39m \n\u001b[32m    698\u001b[39m \u001b[33;03m    If return_cache_object is True, this will return an ActivationCache object, with a bunch of\u001b[39;00m\n\u001b[32m    699\u001b[39m \u001b[33;03m    useful HookedTransformer specific methods, otherwise it will return a dictionary of\u001b[39;00m\n\u001b[32m    700\u001b[39m \u001b[33;03m    activations as in HookedRootModule.\u001b[39;00m\n\u001b[32m    701\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m702\u001b[39m     out, cache_dict = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    703\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremove_batch_dim\u001b[49m\u001b[43m=\u001b[49m\u001b[43mremove_batch_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    704\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m return_cache_object:\n\u001b[32m    706\u001b[39m         cache = ActivationCache(cache_dict, \u001b[38;5;28mself\u001b[39m, has_batch_dim=\u001b[38;5;129;01mnot\u001b[39;00m remove_batch_dim)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/investigaton-NLP-1/.venv/lib/python3.14/site-packages/transformer_lens/hook_points.py:560\u001b[39m, in \u001b[36mHookedRootModule.run_with_cache\u001b[39m\u001b[34m(self, names_filter, device, remove_batch_dim, incl_bwd, reset_hooks_end, clear_contexts, pos_slice, *model_args, **model_kwargs)\u001b[39m\n\u001b[32m    546\u001b[39m cache_dict, fwd, bwd = \u001b[38;5;28mself\u001b[39m.get_caching_hooks(\n\u001b[32m    547\u001b[39m     names_filter,\n\u001b[32m    548\u001b[39m     incl_bwd,\n\u001b[32m   (...)\u001b[39m\u001b[32m    551\u001b[39m     pos_slice=pos_slice,\n\u001b[32m    552\u001b[39m )\n\u001b[32m    554\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.hooks(\n\u001b[32m    555\u001b[39m     fwd_hooks=fwd,\n\u001b[32m    556\u001b[39m     bwd_hooks=bwd,\n\u001b[32m    557\u001b[39m     reset_hooks_end=reset_hooks_end,\n\u001b[32m    558\u001b[39m     clear_contexts=clear_contexts,\n\u001b[32m    559\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m560\u001b[39m     model_out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    561\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m incl_bwd:\n\u001b[32m    562\u001b[39m         model_out.backward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/investigaton-NLP-1/.venv/lib/python3.14/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/investigaton-NLP-1/.venv/lib/python3.14/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/investigaton-NLP-1/.venv/lib/python3.14/site-packages/transformer_lens/HookedTransformer.py:620\u001b[39m, in \u001b[36mHookedTransformer.forward\u001b[39m\u001b[34m(self, input, return_type, loss_per_token, prepend_bos, padding_side, start_at_layer, tokens, shortformer_pos_embed, attention_mask, stop_at_layer, past_kv_cache)\u001b[39m\n\u001b[32m    615\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m shortformer_pos_embed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    616\u001b[39m         shortformer_pos_embed = shortformer_pos_embed.to(\n\u001b[32m    617\u001b[39m             devices.get_device_for_block_index(i, \u001b[38;5;28mself\u001b[39m.cfg)\n\u001b[32m    618\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m     residual = \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    621\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresidual\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Cache contains a list of HookedTransformerKeyValueCache objects, one for each\u001b[39;49;00m\n\u001b[32m    623\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# block\u001b[39;49;00m\n\u001b[32m    624\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_kv_cache_entry\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_kv_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpast_kv_cache\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    625\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    626\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# [batch, pos, d_model]\u001b[39;00m\n\u001b[32m    629\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m stop_at_layer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    630\u001b[39m     \u001b[38;5;66;03m# When we stop at an early layer, we end here rather than doing further computation\u001b[39;00m\n\u001b[32m    631\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m residual\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/investigaton-NLP-1/.venv/lib/python3.14/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/investigaton-NLP-1/.venv/lib/python3.14/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/investigaton-NLP-1/.venv/lib/python3.14/site-packages/transformer_lens/components/transformer_block.py:186\u001b[39m, in \u001b[36mTransformerBlock.forward\u001b[39m\u001b[34m(self, resid_pre, shortformer_pos_embed, past_kv_cache_entry, attention_mask)\u001b[39m\n\u001b[32m    182\u001b[39m     mlp_in = (\n\u001b[32m    183\u001b[39m         resid_mid \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.cfg.use_hook_mlp_in \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.hook_mlp_in(resid_mid.clone())\n\u001b[32m    184\u001b[39m     )\n\u001b[32m    185\u001b[39m     normalized_resid_mid = \u001b[38;5;28mself\u001b[39m.ln2(mlp_in)\n\u001b[32m--> \u001b[39m\u001b[32m186\u001b[39m     mlp_out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply_mlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnormalized_resid_mid\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    187\u001b[39m     resid_post = \u001b[38;5;28mself\u001b[39m.hook_resid_post(resid_mid + mlp_out)  \u001b[38;5;66;03m# [batch, pos, d_model]\u001b[39;00m\n\u001b[32m    188\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.cfg.parallel_attn_mlp:\n\u001b[32m    189\u001b[39m     \u001b[38;5;66;03m# Dumb thing done by GPT-J, both MLP and Attn read from resid_pre and write to resid_post, no resid_mid used.\u001b[39;00m\n\u001b[32m    190\u001b[39m     \u001b[38;5;66;03m# In GPT-J, LN1 and LN2 are tied, in GPT-NeoX they aren't.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/investigaton-NLP-1/.venv/lib/python3.14/site-packages/transformer_lens/components/transformer_block.py:210\u001b[39m, in \u001b[36mTransformerBlock.apply_mlp\u001b[39m\u001b[34m(self, normalized_resid)\u001b[39m\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mapply_mlp\u001b[39m(\n\u001b[32m    203\u001b[39m     \u001b[38;5;28mself\u001b[39m, normalized_resid: Float[torch.Tensor, \u001b[33m\"\u001b[39m\u001b[33mbatch pos d_model\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    204\u001b[39m ) -> Float[torch.Tensor, \u001b[33m\"\u001b[39m\u001b[33mbatch pos d_model\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m    205\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Centralized point where the MLP is applied to the forward pass\u001b[39;00m\n\u001b[32m    206\u001b[39m \n\u001b[32m    207\u001b[39m \u001b[33;03m    Returns:\u001b[39;00m\n\u001b[32m    208\u001b[39m \u001b[33;03m        Float[torch.Tensor, \"batch pos d_model\"]: Our resulting tensor\u001b[39;00m\n\u001b[32m    209\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m210\u001b[39m     mlp_out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnormalized_resid\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# [batch, pos, d_model]\u001b[39;00m\n\u001b[32m    211\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.cfg.use_normalization_before_and_after:\n\u001b[32m    212\u001b[39m         mlp_out = \u001b[38;5;28mself\u001b[39m.ln2_post(mlp_out)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/investigaton-NLP-1/.venv/lib/python3.14/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/investigaton-NLP-1/.venv/lib/python3.14/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/investigaton-NLP-1/.venv/lib/python3.14/site-packages/transformer_lens/components/mlps/gated_mlp.py:75\u001b[39m, in \u001b[36mGatedMLP.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     67\u001b[39m     pre_linear = \u001b[38;5;28mself\u001b[39m.hook_pre_linear(\n\u001b[32m     68\u001b[39m         torch.matmul(x, \u001b[38;5;28mself\u001b[39m.W_in)  \u001b[38;5;66;03m# batch pos d_model, d_model d_mlp -> batch pos d_mlp\u001b[39;00m\n\u001b[32m     69\u001b[39m     )\n\u001b[32m     71\u001b[39m     post_act = \u001b[38;5;28mself\u001b[39m.hook_post(\n\u001b[32m     72\u001b[39m         (\u001b[38;5;28mself\u001b[39m.act_fn(pre_act) * pre_linear) + \u001b[38;5;28mself\u001b[39m.b_in\n\u001b[32m     73\u001b[39m     )  \u001b[38;5;66;03m# [batch, pos, d_mlp]\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbatch_addmm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mb_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mW_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpost_act\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/investigaton-NLP-1/.venv/lib/python3.14/site-packages/transformer_lens/utilities/addmm.py:33\u001b[39m, in \u001b[36mbatch_addmm\u001b[39m\u001b[34m(bias, weight, x)\u001b[39m\n\u001b[32m     31\u001b[39m n_output_features = weight.shape[-\u001b[32m1\u001b[39m]\n\u001b[32m     32\u001b[39m size_out = x.size()[:-\u001b[32m1\u001b[39m] + (n_output_features,)\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m x = \u001b[43mvanilla_addmm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     34\u001b[39m x = x.view(size_out)\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/investigaton-NLP-1/.venv/lib/python3.14/site-packages/transformer_lens/utilities/addmm.py:18\u001b[39m, in \u001b[36mvanilla_addmm\u001b[39m\u001b[34m(input, mat1, mat2)\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mvanilla_addmm\u001b[39m(\n\u001b[32m     10\u001b[39m     \u001b[38;5;28minput\u001b[39m: Float[torch.Tensor, \u001b[33m\"\u001b[39m\u001b[33m... #o\u001b[39m\u001b[33m\"\u001b[39m],  \u001b[38;5;66;03m# Must be broadcastable to \"m o\"\u001b[39;00m\n\u001b[32m     11\u001b[39m     mat1: Float[torch.Tensor, \u001b[33m\"\u001b[39m\u001b[33mm n\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     12\u001b[39m     mat2: Float[torch.Tensor, \u001b[33m\"\u001b[39m\u001b[33mn o\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     13\u001b[39m ) -> Float[torch.Tensor, \u001b[33m\"\u001b[39m\u001b[33mm o\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m     14\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Typechecked version of torch.addmm.\u001b[39;00m\n\u001b[32m     15\u001b[39m \n\u001b[32m     16\u001b[39m \u001b[33;03m    Note that both mat1 and mat2 *must* be 2d matrices.\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43maddmm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmat1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmat2\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "compare(\"Once the glass shattered, there was no way back.\",\n",
    "        \"When she sent the angry email, the relationship changed permanently.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebfe541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG similarity: 0.5718832471264863\n",
      "SAE similarity: 0.534549355506897\n"
     ]
    }
   ],
   "source": [
    "compare(\"He invested everything for a chance at a breakthrough.\",\n",
    "        \"She stepped onto the stage knowing the risk was worth the opportunity.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62c026cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG similarity: 0.9285133402558516\n",
      "SAE similarity: 0.5873538255691528\n"
     ]
    }
   ],
   "source": [
    "compare('She closed the window because the cold wind was coming in.',\n",
    "        'She shut the window to keep the chilly breeze out.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "70afca36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG similarity: 0.9019049688465273\n",
      "SAE similarity: 0.6499947905540466\n"
     ]
    }
   ],
   "source": [
    "compare('He hurried to catch the last train before midnight.',\n",
    "        'He rushed to board the final train that left just before twelve.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "08d96d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG similarity: 0.8380246617842546\n",
      "SAE similarity: 0.6573800444602966\n"
     ]
    }
   ],
   "source": [
    "compare('The book was so captivating that she finished it in one night.',\n",
    "        'She read the whole novel in a single evening because it was irresistible.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "92738925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG similarity: 0.8239608511256304\n",
      "SAE similarity: 0.589231014251709\n"
     ]
    }
   ],
   "source": [
    "compare('The dog barked loudly at the mail carrier.',\n",
    "        'The dog made a racket when the postal worker approached.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a2398195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG similarity: 0.5298888996725823\n",
      "SAE similarity: 0.5248370170593262\n"
     ]
    }
   ],
   "source": [
    "compare('The cat slept on the warm radiator.',\n",
    "        'Quantum computers require extremely low temperatures to operate.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bf9e6690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG similarity: 0.34518207932378536\n",
      "SAE similarity: 0.383361279964447\n"
     ]
    }
   ],
   "source": [
    "compare('The nebula glowed faintly as the telescope adjusted its focus.',\n",
    "        'I forgot to buy onions for the pasta sauce.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "77ce3bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG similarity: 0.31755464184461646\n",
      "SAE similarity: 0.31813913583755493\n"
     ]
    }
   ],
   "source": [
    "compare('The café down the street started selling homemade lemonade.',\n",
    "        'Saturn’s rings are mostly composed of ice particles.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c57a8285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG similarity: 0.3717168859381351\n",
      "SAE similarity: 0.43883946537971497\n"
     ]
    }
   ],
   "source": [
    "compare('My shoes got soaked when it started raining unexpectedly.',\n",
    "        'The server must be restarted after applying the new kernel patch.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5ca76b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG similarity: 0.3164769270993337\n",
      "SAE similarity: 0.33727002143859863\n"
     ]
    }
   ],
   "source": [
    "compare('What if my child just refuses to take responsibility for their actions? How do I get them to understand the importance of being accountable?',\n",
    "        'How many days did I spend on camping trips in the United States this year?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7503384c",
   "metadata": {},
   "source": [
    "Aún cuando están relacionados conceptualmente y no semánticamente, RAG es mejor que SAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7aed7230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG similarity: 0.4902988564590743\n",
      "SAE similarity: 0.3685685396194458\n"
     ]
    }
   ],
   "source": [
    "compare('If you pack too many tools into a small backpack, something essential will always get left behind.',\n",
    "        'A neural network with fixed width can’t memorize new patterns without forgetting some of the old ones.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "43389ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG similarity: 0.540741589430252\n",
      "SAE similarity: 0.47643065452575684\n"
     ]
    }
   ],
   "source": [
    "compare('A single spark landing in dry grass can turn into a wildfire by nightfall.',\n",
    "        'One unstable nucleotide in a cell can initiate a cascade of replication errors.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "42391692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG similarity: 0.5917122431442312\n",
      "SAE similarity: 0.3543633222579956\n"
     ]
    }
   ],
   "source": [
    "compare('Watering a plant twice doesn’t make it grow twice as fast.',\n",
    "        'Doubling your training epochs rarely doubles your model’s accuracy.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
